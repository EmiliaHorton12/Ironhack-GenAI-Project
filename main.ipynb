{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # natural language toolkit\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Storage and Retrieval\n",
    "### Loading the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the document\n",
    "file_path = r\"C:\\Users\\PC\\OneDrive\\Documentos\\Bootcamp\\Mini project gen ai\\Piranesi - Susanna Clark.pdf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents into pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and split the document\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIRANESI\n",
      "For Colin\n",
      "‘I am the great scholar, the magician, the adept, who is doing the\n",
      "experiment. Of course I need subjects to do it on.’\n",
      "The Magician’s Nephew, C. S. Lewis\n",
      "‘People call me a philosopher or a scientist or an anthropologist. I am\n",
      "none of those things. I am an anamnesiologist. I study what has been\n",
      "forgotten. I divine what has disappeared utterly. I work with absences, with\n",
      "silences, with curious gaps between things. I am really more of a magician\n",
      "than anything else.’\n",
      "Laurence Arne-Sayles, interview in The Secret Garden, May 1976\n",
      "CONTENTS\n",
      " \n",
      "1. PART 1: PIRANESI\n",
      "2. PART 2: THE OTHER\n",
      "3. PART 3: THE PROPHET\n",
      "4. PART 4: 16\n",
      "5. PART 5: VALENTINE KETTERLEY\n",
      "6. PART 6: WAVE\n",
      "7. PART 7: MATTHEW ROSE SORENSEN\n",
      "8. NOTE ON THE AUTHOR\n"
     ]
    }
   ],
   "source": [
    "# Print text from the first pages\n",
    "print(pages[0].page_content[:1000])  # Show first 1000 characters\n",
    "print(pages[1].page_content[:1000])\n",
    "print(pages[3].page_content[:1000])\n",
    "print(pages[4].page_content[:1000]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split pages into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=20000, chunk_overlap=300)\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Print the length of the text content in the first chunk\n",
    "print(len(chunks[0].page_content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_21988\\2260860997.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "#embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "#embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # This will load the .env file\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"API key not found. Please check your .env file.\")\n",
    "else:\n",
    "    print(\"API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB created with document embeddings.\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(chunks, embeddings, persist_directory=\"./chroma_db\")\n",
    "print(\"ChromaDB created with document embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"How did Matthew become Piranesi?\" # User question\n",
    "retrieved_docs = db.similarity_search(user_question, k=10) # k is the number of documents to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display top results\n",
    "for i, doc in enumerate(retrieved_docs[:1]): # Display top 3 results\n",
    "    print(f\"Document {i+1}:\\n{doc.page_content[36:1000]}\") # Display content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing content for GenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_document_prompt(docs):\n",
    "    prompt = \"\\n\"\n",
    "    for doc in docs:\n",
    "        prompt += \"\\nContent:\\n\"\n",
    "        prompt += doc.page_content + \"\\n\\n\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context formatted for GPT model.\n"
     ]
    }
   ],
   "source": [
    "# Generate a formatted context from the retrieved documents\n",
    "formatted_context = _get_document_prompt(retrieved_docs)\n",
    "print(\"Context formatted for GPT model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatBot Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt constructed.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "## SYSTEM ROLE\n",
    "You are an expert on the book *Piranesi* by Sussanna Clarke. Your job is to: \n",
    "-Recognize characters, places, objects and events in the book.\n",
    "-Provide detailed explanations of characters, locations and themes.\n",
    "-Analyze and corelate: notice relationships between characters (e.g., when one character has multiple identities or names) and explain them.\n",
    "-Answer questions about the book, including character motivations and plot points.\n",
    "-Provide summaries of chapters or sections of the book.\n",
    "-Explain the significance of specific quotes or passages.\n",
    "-Clarify and interpret: if a user asks about symbolic meanings or hidden themes, provide analyses and interpretations.\n",
    "-Provide context: if a user asks about a specific event or character, provide background information to help them understand the significance of that event or character.\n",
    "If unsure, say 'I don't know' and adjuct what you think the answer is.\n",
    "\n",
    "## USER QUESTION\n",
    "The user has asked: \n",
    "\"{user_question}\"\n",
    "\n",
    "## CONTEXT\n",
    "Here is the relevant content from the book:  \n",
    "'''\n",
    "{formatted_context}\n",
    "'''\n",
    "\n",
    "## GUIDELINES\n",
    "1. **Accuracy**:  \n",
    "   - Character recognition: provide full identity of the characters (including alternate names), their role in the story, and any major developments.\n",
    "   - Place recognition: provide full names of places, their significance in the story, and any major events that occur there.\n",
    "   - If the answer cannot be found, explicitly state: \"I couldn't find the answer in the book\", and ask the user to provide more context or details.\n",
    "   - Provide page numbers for any specific quotes or passages you reference in your answer.\n",
    "   - Warn the user about speculative content: if you are unsure about a specific detail, make it clear that you are speculating and provide your reasoning.\n",
    "   - Spoiler sensitivity: if the user asks about a major plot twist, warn them before reavealing the information.\n",
    "\n",
    "2. **Transparency**:   \n",
    "   - Warn the user about speculative content: if you are unsure about a specific detail, make it clear that you are speculating and provide your reasoning. \n",
    "\n",
    "3. **Clarity**:  \n",
    "   - Your response should be clear and easy to understand.\n",
    "   - Format your response in Markdown for readability.  \n",
    "\n",
    "## TASK\n",
    "1. Answer the user's question **directly** if possible.  \n",
    "2. Point the user to relevant parts of the documentation.  \n",
    "3. Provide the response in the following format:\n",
    "\n",
    "## RESPONSE FORMAT\n",
    "'''\n",
    "# [Brief Title of the Answer]\n",
    "[Answer in simple, clear text.]\n",
    "\n",
    "**Source**:  \n",
    "• [Book Title], Page(s): [...]\n",
    "'''\n",
    "\"\"\"\n",
    "print(\"Prompt constructed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPT client and parameters\n",
    "client = openai.OpenAI()\n",
    "model_params = {\n",
    "    'model': 'gpt-4o',\n",
    "    'temperature': 0.7,  # Increase creativity\n",
    "    'max_tokens': 4000,  # Allow for longer responses\n",
    "    'top_p': 0.9,        # Use nucleus sampling\n",
    "    'frequency_penalty': 0.5,  # Reduce repetition\n",
    "    'presence_penalty': 0.6    # Encourage new topics\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'user', 'content': prompt}]\n",
    "completion = client.chat.completions.create(messages=messages, **model_params, timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'''\n",
      "# How Matthew Became Piranesi\n",
      "\n",
      "Matthew Rose Sorensen becomes Piranesi as a result of his experiences in the mysterious world he finds himself in, which is referred to as the House. This transformation is both physical and psychological. Initially, Matthew is an academic who enters this strange world through the manipulations of Laurence Arne-Sayles (known as the Other). Over time, due to isolation and the unique nature of the House, Matthew loses his former identity and adopts the name Piranesi. The environment of endless halls filled with statues and oceans affects his memory and perception, leading him to forget much of his past life.\n",
      "\n",
      "This transformation highlights themes of identity, memory, and reality within Susanna Clarke's novel. The change from Matthew to Piranesi symbolizes a loss of self but also a new way of being that is deeply connected to the environment he inhabits.\n",
      "\n",
      "**Source**:  \n",
      "• *Piranesi* by Susanna Clarke, specific pages not provided.\n",
      "'''\n"
     ]
    }
   ],
   "source": [
    "answer = completion.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
